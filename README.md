# Machine Learning
Neste repositório vou adicionar minha evolução em aplicações de algoritmos machine learning utilizando alguns conjuntos de dados.

***1 - Validação cruzada e aleatoriedade inicial***
> Inicialmente aplicamos o SEED para ter um aumento na accuracy, mas para evitar uma decisão baseada em uma aleatoriedade, ou seja ficarmos menos suscetíveis a ela utilizamos o cross_validade, também para evitar que no conjunto treino e teste onde inicialmente foi usada a técnica holdout tenha sido separado de uma maneira ruim decidimos treinas e testar mais de uma vez para ter uma estimativa, treinando de testando o conjunto de dados de maneira cruzada utilidando KFold, no algoritmo que usava o DecisionTreeClassifier no cross_validate que até então estava definido com cv=5, decidimos colocar o nosso gerador de validação (KFold), uma vez cross_validate aceita esse parâmetro e tal objeto Kfold, permite a aleatoriedade quando shuffle = True. Mais adiante foi notado que com o KFold tem chance de ocorrer desbalanceamento entre, diferente do train_test_split que possuaia a váriavel stratified para fazer o balanceamento entre as classes aqui foi decidido usar o StratifiedKFold. Levando em consideração que o algoritmo precisa se capaz de se adaptar a novos dados, pensando nisso agrupamos os dados que já possuiamos no nosso conjunto de dados utilizamos o GroupKFold para que novos dados tivessem um grupo específico para serem alocados, e como  algortimos SVM são sensíveis a discrêpancias nas features aplicamos o StandardScaler removendo a média e escalonando a variância. Como o processo no GroupKFold é rodado sempre de acordo com os grupos e splits utilizamos o pipeline para fazer em sequência scaler e modelo.
 
