# Machine Learning
Neste repositório vou adicionar minha evolução em aplicações de algoritmos machine learning utilizando alguns conjuntos de dados.

***1 - Validação cruzada e aleatoriedade inicial***
> Inicialmente aplicamos o SEED para ter um aumento na accuracy, mas para evitar uma decisão baseada em uma aleatoriedade, ou seja ficarmos menos suscetíveis a ela utilizamos o cross_validade, também para evitar que no conjunto treino e teste onde inicialmente foi usada a técnica holdout tenha sido separado de uma maneira ruim decidimos treinar e testar mais de uma vez para ter uma estimativa, para isso treinamos e testamos o conjunto de dados de maneira cruzada utilidando KFold. No algoritmo que usava o DecisionTreeClassifier no cross_validate que até então estava definido com cv=5, decidimos colocar o nosso gerador de validação (KFold), uma vez cross_validate aceita esse parâmetro e tal objeto Kfold, permite a aleatoriedade quando shuffle = True. Mais adiante foi notado que com o KFold tem chance de ocorrer desbalanceamento entre classes, diferente do train_test_split que possuia a váriavel stratified para fazer o balanceamento entre as classes, tivemos que  usar o StratifiedKFold para solucionar o problema. Levando em consideração que o algoritmo precisa se capaz de se adaptar a novos dados, nisso agrupamos os dados que já possuiamos no nosso conjunto de dados utilizando o GroupKFold para que novos dados tivessem um grupo específico para serem alocados, e como algortimos SVM são sensíveis a discrêpancias nas features aplicamos o StandardScaler removendo a média e escalonando a variância. Como o processo no GroupKFold é rodado sempre de acordo com os grupos e splits utilizamos o pipeline para fazer em sequência, scaler e modelo.
 
